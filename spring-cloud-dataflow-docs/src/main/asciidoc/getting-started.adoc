[[getting-started]]
= Getting started

[partintro]
--
If you're just getting started with Spring Cloud Data Flow, this is the section
for you! Here we answer the basic "`what?`", "`how?`" and "`why?`" questions. You'll
find a gentle introduction to Spring Cloud Data Flow along with installation instructions.
We'll then build our first Spring Cloud Data Flow application, discussing some core principles as
we go.
--

[[getting-started-system-requirements]]
== System Requirements

You need Java installed (Java 7 or better, we recommend Java 8), and to build, you need to have Maven installed as well.

You also need to have link:http://redis.io/[Redis] installed and running if you plan on running a local system, or to run the included tests.

[[getting-started-deploying-spring-cloud-dataflow]]
== Deploying Spring Cloud Data Flow

=== Deploying 'local'
. Download the Spring Cloud Data Flow Server and Shell apps:
+
[subs=attributes]
```
wget http://repo.spring.io/milestone/org/springframework/cloud/spring-cloud-dataflow-server-local/{project-version}/spring-cloud-dataflow-server-local-{project-version}.jar

wget http://repo.spring.io/milestone/org/springframework/cloud/spring-cloud-dataflow-shell/{project-version}/spring-cloud-dataflow-shell-{project-version}.jar
```
+
. Launch the Data Flow Server
+
.. Since the Data Flow Server is a Spring Boot application, you can run it just by using `java -jar`.
+
[subs=attributes]
```
$ java -jar spring-cloud-dataflow-server-local-{project-version}.jar
```
+
.. Running with Custom Maven Settings and/or Behind a Proxy
If you want to override specific maven configuration properties (remote repositories, etc.) and/or run the Data Flow Server behind a proxy,
you need to specify those properties as command line arguments when starting the Data Flow Server. For example:
+
[subs=attributes]
```
$ java -jar spring-cloud-dataflow-server-local-{project-version}.jar --maven.localRepository=mylocal --maven.remoteRepositories=repo1,repo2 --maven.offline=true
--maven.proxy.protocol=https --maven.proxy.host=host1 --maven.proxy.port=8090 --maven.proxy.non_proxy_hosts='host2|host3' --maven.proxy.auth.username=user1 --maven.proxy.auth.password=passwd
```
+
By default, the protocol is set to `http`. You can omit the auth properties if the proxy doesn't need a username and password.
+
By default, the maven `localRepository` is set to `${user.home}/.m2/repository/`,
and `https://repo.spring.io/libs-snapshot` will be the only remote repository.
+
You can also use environment variables to specify the maven/proxy properties:
+
```
export MAVEN_LOCAL_REPOSITORY=mylocalMavenRepo
export MAVEN_REMOTE_REPOSITORIES=repo1,repo2
export MAVEN_OFFLINE=true
export MAVEN_PROXY_PROTOCOL=https
export MAVEN_PROXY_HOST=host1
export MAVEN_PROXY_PORT=8090
export MAVEN_PROXY_NON_PROXY_HOSTS='host2|host3'
export MAVEN_PROXY_AUTH_USERNAME=user1
export MAVEN_PROXY_AUTH_PASSWORD=passwd
```
+
. Launch the shell:
+
[subs=attributes]
```
$ java -jar spring-cloud-dataflow-shell-{project-version}.jar
```
+
If the Data Flow Server and shell are not running on the same host, point the shell to the Data Flow server:
+
```
server-unknown:>dataflow config server http://dataflow-server.cfapps.io
Successfully targeted http://dataflow-server.cfapps.io
dataflow:>
```
+
. You can now use the shell commands to list available applications (source/processors/sink) and create streams. For example:
+
```
dataflow:>stream create --name httptest --definition "http --server.port=9000 | log" --deploy
```
+
NOTE: You will need to wait a little while until the apps are actually deployed successfully
before posting data.  Look in the log file of the Data Flow server for the location of the log
files for the `http` and `log` applications.  Tail the log file for each application to verify
the application has started.  
+
Now post some data
```
dataflow:> http post --target http://localhost:9000 --data "hello world"
```
Look to see if `hello world` ended up in log files for the `log` application.

